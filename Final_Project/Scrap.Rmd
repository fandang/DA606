---
title: "DA 606 Final Project"
author: "Dan Fanelli"
output: html_document
---

![Just Politics](politics.png)

# 1. Introduction: 

__Research question:__

What can we learn about the American presidential election process by studying the candidates:

* Number of Contributions
* Total Contributions
* Average Contribution
* Where the candidate falls on the political spectrum
* Who received the largest donations?
* How big are the donation? (1st-3rd Quartiles)
* Are there donation patterns across the left-to-right political spectrum?
* Are there relationsips between donations and other features of the candidate?
* Does testing a subset of the data, due to hardware limits, produce a statistically accurate snapshot of the donations?

__Why we should care:__

* We should care about the number of, sizes, and totals of contributions to help us see if our government is truly serving its people, or rather serving special interests. 

![America Votes](america_votes.png)

# 2. Data: 

__Data collection:__

* Election Data was downloaded and loaded from: http://www.fec.gov/disclosurep/PDownload.do
* Political Spectrum information about the candidates was taken from: http://www.huffingtonpost.com/findthebest-/every-2016-candidate-from_b_7562176.html

__Cases:__

* Each case in this study was an individual campaign contribution.

__Variables:__ 

* The two (groups of) variables that will be studied are 1) Contributions, and 2) Candidate Political Spectrum Score:
* Note that after analysis, the most relevant of the contribution statistics will be used (of contribution total, contribution mean, and contribution_count)

__Type of study:__ 

This is an observational study, and not an experiment one? (Explain how you've arrived at your conclusion using information on the sampling and/or experimental design.)

__Scope of inference:__ 

* Generalizability: The population of interest is the American voting public of 2016. The findings from this analysis need not be generalized as they are the full representation of that data. They may be generalizable to some extent from election year to election year, but as national situations and priorities change, the dynamics of the election model may change too. There is bias in this data in assuming that all contribution sources are the same.  There are many attributes that make up an individual, and none of these have been taken into account in this project.

* Causality: I believe the data can be used to establish causal links between the variables of interest. The average donation sizes, in my opinion, seem to be the greatest indicator of the wishes of the Americans with less money, while the largest donations will show the wishes of the Americans with the most money.

# 3. Exploratory data analysis: 

__3a) The Candidates, Donations, and the Candidates' Spectrum:__

```{r warning=FALSE, message=FALSE, echo=FALSE}
library(knitr)
library(ggplot2)
library(sqldf)

#SAMPLE_SIZE <- 'ALL'
SAMPLE_SIZE <- 25000
# Its the WRITING that takes most the time!!!!
DO_WRITE_SAMPLES <- FALSE 

# this is a general plot method for use during part 3 exploration
util_plot_stat <- function(df, the_title, the_y_title, the_aes, the_year){
  plt <- ggplot(df, the_aes)
  plt <- plt + stat_summary(fun.y=identity, geom="bar")
  plt <- plt + scale_fill_manual(values=c("red", "blue", "green"))
  plt <- plt + theme(axis.text.x = element_text(angle = 90, hjust = 1))
  plt <- plt + labs(title=paste(the_title, the_year) ,x="Candidate", y=the_y_title) 
  show(plt)
}

```

The base donations data is loaded. The finished product relies on reports generated from 2016_donations_ALL.csv (about 225 MB), while during development, smaller samples are used, such as 2016_donations_5000.csv.  Below is the code that generated those samples based on the large dataset, as well as the loading of the csv into a data frame:

```{r warning=FALSE, message=FALSE, echo=FALSE}
write_sample_set <- function(sample_size, year){
  print(Sys.time())
  all_csv_path <- paste0(year,"_donations_ALL.csv")
  df <- read.csv(all_csv_path, header=TRUE)

  if(sample_size > 0){
    # this is where the SUBSET is created:
    df <- df[sample(nrow(df), sample_size), ]
  }
  print(kable(head(df)))
  file_name <- paste0(year,"_donations_",nrow(df),".csv")
  write.csv(df, file = file_name)
  print(Sys.time())
}

if(DO_WRITE_SAMPLES){
  #write_sample_set(SAMPLE_SIZE, 2012)
  write_sample_set(SAMPLE_SIZE, 2016)
}

```

Next, since the presidential candidates were a small set of data, data was manually copied from http://www.huffingtonpost.com/findthebest-/every-2016-candidate-from_b_7562176.html into a data frame: 

```{r warning=FALSE, message=FALSE}
util_get_data_frame <- function(the_year){
  file_name <- paste0(the_year,"_donations_",SAMPLE_SIZE,".csv")
  df <- read.csv(file_name, header=TRUE, row.names=NULL)
  df$contb_receipt_amt <- as.numeric(as.character(df$contb_receipt_amt))
  df <- df[with(df, order(-contb_receipt_amt, contb_receipt_amt)), ]
  df$millions <- df$contb_receipt_amt / 1000000

  
  df[,"spectrum_score"] <- 0.0

  df[df$cand_nm == "Cruz, Rafael Edward 'Ted'", "spectrum_score"] <- 8
  df[df$cand_nm == "Rubio, Marco", "spectrum_score"] <- 6.8
  df[df$cand_nm == "Bush, Jeb", "spectrum_score"] <- 4.8
  df[df$cand_nm == "Clinton, Hillary Rodham", "spectrum_score"] <- -6.8
  df[df$cand_nm == "Walker, Scott", "spectrum_score"] <- 6.8
  df[df$cand_nm == "Jindal, Bobby", "spectrum_score"] <- 7.2
  df[df$cand_nm == "Christie, Christopher J.", "spectrum_score"] <- 2.5
  df[df$cand_nm == "Fiorina, Carly", "spectrum_score"] <- 4.8
  df[df$cand_nm == "Graham, Lindsey O.", "spectrum_score"] <- 6
  df[df$cand_nm == "Carson, Benjamin S.", "spectrum_score"] <- 5.8
  df[df$cand_nm == "O'Malley, Martin Joseph", "spectrum_score"] <- -4.5
  df[df$cand_nm == "Kasich, John R.", "spectrum_score"] <- 5
  df[df$cand_nm == "Sanders, Bernard", "spectrum_score"] <- -8.5
  df[df$cand_nm == "Huckabee, Mike", "spectrum_score"] <- 5
  df[df$cand_nm == "Trump, Donald J.", "spectrum_score"] <- 4
  df[df$cand_nm == "Paul, Rand", "spectrum_score"] <- 2.2
  df[df$cand_nm == "Webb, James Henry Jr.", "spectrum_score"] <- -3.2
  df[df$cand_nm == "Stein, Jill", "spectrum_score"] <- -10

  df$the_color <- ifelse(df$spectrum_score < 0, '#FF0000', '#0000FF')

  return (df)
}
```


```{r warning=FALSE, message=FALSE}
df <- util_get_data_frame(2016)
kable(head(df))
```

How about contributions by spectrum score?

Copied from Average Joe:

```{r warning=FALSE, message=FALSE}

contribution_means <- aggregate(df$contb_receipt_amt, by=list(Category=df$cand_nm, clr=df$the_color), FUN=mean)
colnames(contribution_means) <- c('candidate', 'the_color', 'dollars')
kable(head(contribution_means[,c(1,3)]))
the_aes <- aes(fill=the_color, x=reorder(candidate, -dollars), y=dollars)

plt <- ggplot(contribution_means, the_aes)
plt <- plt + stat_summary(fun.y=identity, geom="bar")

#plt <- plt + scale_fill_manual(values=c("red", "blue", "green"))
plt <- plt + scale_colour_gradient(limits=c(-10, 10), low="blue", high="red", space="Lab")

plt <- plt + theme(axis.text.x = element_text(angle = 90, hjust = 1))
plt <- plt + labs(title=paste("The Goods", 2016) ,x="Candidate", y="Dollars") 
#plt <- plt + geom_point(x=df$cand_nm, y=df$spectrum_score)
show(plt)

```

#### Analysis #A: Total Contributions

Let's take a look at the contributions per candidate:

```{r warning=FALSE, message=FALSE}

contribution_sums <- aggregate(df$millions, by=list(cand=df$cand_nm, clr=df$the_color), FUN=sum)

colnames(contribution_sums) <- c('candidate', 'the_color', 'millions')
kable(head(contribution_sums[,c(1,3)]))
the_aes <- aes(fill=the_color, x=reorder(candidate, -millions), y=millions)
util_plot_stat(contribution_sums, "Total Contributions", "Millions", the_aes, 2016)      

```

Now let's take a look at the contributions by party:

```{r warning=FALSE, message=FALSE}

party_sums <- aggregate(df$millions, by=list(cand=df$the_color, clr=df$the_color), FUN=sum)

colnames(party_sums) <- c('party', 'the_color', 'millions')
kable(head(party_sums[,c(1,3)]))
the_aes <- aes(fill=the_color, x=reorder(party, -millions), y=millions)
util_plot_stat(party_sums, "Total Contributions", "Millions", the_aes, 2016)      

```

#### Analysis #B: Average Joe (mean contributions)

Let's take a look at the MEAN contributions per candidate:

```{r warning=FALSE, message=FALSE}

contribution_means <- aggregate(df$contb_receipt_amt, by=list(Category=df$cand_nm, clr=df$the_color), FUN=mean)
colnames(contribution_means) <- c('candidate', 'the_color', 'dollars')
kable(head(contribution_means[,c(1,3)]))
the_aes <- aes(fill=the_color, x=reorder(candidate, -dollars), y=dollars)
util_plot_stat(contribution_means, "Mean Contributions", "Dollars", the_aes, 2016)      

```

#### Analysis #C: Contribution Counts

How many UNIQUE contributions per candidate:

```{r warning=FALSE, message=FALSE}
contribution_counts <- aggregate(df$contb_receipt_amt, by=list(Category=df$cand_nm, clr=df$the_color), FUN=length)


colnames(contribution_counts) <- c('candidate','the_color', 'contr_count')
kable(head(contribution_counts[,c(1,3)]))
the_aes <- aes(fill=the_color, x=reorder(candidate, -contr_count), y=contr_count)
util_plot_stat(contribution_counts, "Number of Contributions", "Count", the_aes, 2016)      

```


# 4. Inference: 

If your data fails some conditions and you can't use a theoretical method, then you should use simulation. If you can use both methods, then you should use both methods. It is your responsibility to figure out the appropriate methodology.

* Check conditions
* Theoretical inference (if possible) - hypothesis test and confidence interval
* Simulation based inference - hypothesis test and confidence interval
* Brief description of methodology that reflects your conceptual understanding

# 5. Conclusion

__My Findings:__

* There were other interesting data sets available, such as WHO the donations came from, when in the campaign lifecycle they came, etc.
* I normally pictured these data sets with very "distinct" columns, ie - with truly distinct meanings.  This data set showed me that you can create fields with different meanings, all based on the same data (ie - dollars per contribution, total contributions, total number of contributions - all the same data, but different underlying meanings.)
* Based on this project, some questions that I would be curious about in the future are:
  + Which types of groups are donating the large amounts?
  + Which companies are truly just 'bribing' their candidates by contributing to all the candidates.
  + System memory limits really were an issue.  I knew that this was a problem in industry, but was not really expecting to get so many out-of-memory errors running Rmd scripts.

Write a brief summary of your findings without repeating your statements from earlier. Also include a discussion of what you have learned about your research question and the data you collected. You may also want to include ideas for possible future research.



```{r warning=FALSE, message=FALSE}
library(knitr)
library(ggplot2)
library(sqldf)


#df <- read.csv("2016_donations_ALL.csv", header=TRUE, row.names=NULL)
df <- read.csv("2016_donations_25000.csv", header=TRUE, row.names=NULL)
df$contb_receipt_amt <- as.numeric(as.character(df$contb_receipt_amt))
df <- df[with(df, order(-contb_receipt_amt, contb_receipt_amt)), ]

df[,"spectrum_score"] <- 0.0

df[df$cand_nm == "Cruz, Rafael Edward 'Ted'", "spectrum_score"] <- 8
df[df$cand_nm == "Rubio, Marco", "spectrum_score"] <- 6.8
df[df$cand_nm == "Bush, Jeb", "spectrum_score"] <- 4.8
df[df$cand_nm == "Clinton, Hillary Rodham", "spectrum_score"] <- -6.8
df[df$cand_nm == "Christie, Christopher J.", "spectrum_score"] <- 2.5
df[df$cand_nm == "Fiorina, Carly", "spectrum_score"] <- 4.8
df[df$cand_nm == "Carson, Benjamin S.", "spectrum_score"] <- 5.8
df[df$cand_nm == "Kasich, John R.", "spectrum_score"] <- 5
df[df$cand_nm == "Sanders, Bernard", "spectrum_score"] <- -8.5
df[df$cand_nm == "Trump, Donald J.", "spectrum_score"] <- 4
df[df$cand_nm == "Paul, Rand", "spectrum_score"] <- 2.2

#kable(head(df, n=10))
cols_to_trash <- c(1,2,3,5,9,13,14,15,16,17,18,19,20)
# Cutting it down to just the candidates I recognize!
df <- df[df$spectrum_score != 0.0,-cols_to_trash]

kable(head(df, n=10))

summary_df <- sqldf("select cand_nm, count(*) as contribution_count, sum(contb_receipt_amt) as contribution_total, (sum(contb_receipt_amt)/count(*)) as contribution_mean, max(spectrum_score) as spectrum_score from df group by cand_nm order by spectrum_score desc ", stringsAsFactors = FALSE)


summary_df$party <- ifelse(summary_df$spectrum_score < 0, 'Democrat', 'Republican')

summary_df$millions <- summary_df$contribution_total / 1000000

kable(summary_df)



ggplot(summary_df, aes(cand_nm, millions)) + labs(title="2016 Contribution Totals" , x="Candidate", y="Contribution Total - Millions") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + geom_point(aes(shape=party, colour=spectrum_score, size=contribution_total)) + scale_colour_gradient(limits=c(-10, 10), low="navy", high="red")


ggplot(summary_df, aes(cand_nm, spectrum_score)) + labs(title="2016 Contribution Sums" , x="Candidate", y="Spectrum Score") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + geom_point(aes(shape=party, colour=spectrum_score, size=contribution_total)) + scale_colour_gradient(limits=c(-10, 10), low="navy", high="red")


#+ stat_summary(fun.y=identity, geom="bar")
#+ scale_fill_manual(values=c("red", "blue", "green"))

fit <- lm(spectrum_score~contribution_count+contribution_total+contribution_mean+party, data=summary_df)

summary(fit)
#plot(fit)

plot(summary_df$spectrum_score, summary_df$contribution_total)

hist(summary_df$millions, breaks = 10)

```
